{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time  temperature_2m_mean (¬∞C)  temperature_2m_max (¬∞C)  \\\n",
      "143    1994-05-24                      26.0                     28.9   \n",
      "178    1994-06-28                      27.0                     28.2   \n",
      "494    1995-05-10                      27.1                     30.1   \n",
      "497    1995-05-13                      26.2                     27.3   \n",
      "500    1995-05-16                      26.1                     26.4   \n",
      "...           ...                       ...                      ...   \n",
      "11104  2024-05-27                      27.0                     27.8   \n",
      "11170  2024-08-01                      26.9                     27.9   \n",
      "11215  2024-09-15                      25.8                     26.9   \n",
      "11255  2024-10-25                      25.1                     25.8   \n",
      "11517  2025-07-14                      26.3                     27.8   \n",
      "\n",
      "       temperature_2m_min (¬∞C)  sunshine_duration (s)  daylight_duration (s)  \\\n",
      "143                       24.4                    0.0               48016.72   \n",
      "178                       25.6                    0.0               48611.75   \n",
      "494                       24.4                    0.0               47279.18   \n",
      "497                       25.2                    0.0               47452.45   \n",
      "500                       25.7                    0.0               47617.59   \n",
      "...                        ...                    ...                    ...   \n",
      "11104                     26.3                    0.0               48170.05   \n",
      "11170                     25.9                    0.0               47337.92   \n",
      "11215                     24.9                    0.0               44178.35   \n",
      "11255                     24.2                    0.0               41142.98   \n",
      "11517                     25.2                    0.0               48207.80   \n",
      "\n",
      "       shortwave_radiation_sum (MJ/m¬≤)  \n",
      "143                               5.98  \n",
      "178                               4.91  \n",
      "494                               4.88  \n",
      "497                               5.18  \n",
      "500                               1.57  \n",
      "...                                ...  \n",
      "11104                             2.46  \n",
      "11170                             4.96  \n",
      "11215                             5.44  \n",
      "11255                             1.42  \n",
      "11517                             5.02  \n",
      "\n",
      "[172 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/history.csv')\n",
    "#print(df.head())\n",
    "#print(df.columns)\n",
    "\n",
    "#Specifying columns to check for zeros\n",
    "cols_to_check = [\"sunshine_duration (s)\", \"daylight_duration (s)\", \"shortwave_radiation_sum (MJ/m¬≤)\"]\n",
    "\n",
    "#Checking for zeros in the specified columns\n",
    "rows_with_zero = df[(df[cols_to_check] == 0).any(axis=1)]\n",
    "\n",
    "print(rows_with_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e72b9feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 172 days with zero sunshine duration\n",
      "Results saved to 'data/zero_sunshine_days.csv'\n",
      "\n",
      "Preview:\n",
      "           time  sunshine_duration (s)  temperature_2m_mean (¬∞C)\n",
      "143  1994-05-24                    0.0                      26.0\n",
      "178  1994-06-28                    0.0                      27.0\n",
      "494  1995-05-10                    0.0                      27.1\n",
      "497  1995-05-13                    0.0                      26.2\n",
      "500  1995-05-16                    0.0                      26.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# If you uncomment the header line in history.csv first, use this simpler version:\n",
    "df = pd.read_csv('data/history.csv')\n",
    "\n",
    "# Filter rows where sunshine_duration is 0.0\n",
    "zero_sunshine_rows = df[df['sunshine_duration (s)'] == 0.0]\n",
    "\n",
    "# Save to a new CSV file\n",
    "zero_sunshine_rows.to_csv('data/zero_sunshine_days.csv', index=False)\n",
    "\n",
    "print(f\"Found {len(zero_sunshine_rows)} days with zero sunshine duration\")\n",
    "print(f\"Results saved to 'data/zero_sunshine_days.csv'\")\n",
    "print(\"\\nPreview:\")\n",
    "print(zero_sunshine_rows[['time', 'sunshine_duration (s)', 'temperature_2m_mean (¬∞C)']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13bcf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Processing 172 rows across 32 years\n",
      "üåê Making approximately 32 API calls...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 1994 (2 days to check)...\n",
      "  ‚úÖ 1994-05-24: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1994-06-28: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:   3%|‚ñé         | 1/32 [00:03<01:38,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 1995 (7 days to check)...\n",
      "  ‚úÖ 1995-05-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1995-05-13: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1995-05-16: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1995-07-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1995-10-30: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1995-11-01: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1995-11-09: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:   6%|‚ñã         | 2/32 [00:05<01:22,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 1996 (8 days to check)...\n",
      "  ‚úÖ 1996-06-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-06-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-06-26: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-06-30: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-08-07: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-08-21: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-10-27: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1996-10-28: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:   9%|‚ñâ         | 3/32 [00:08<01:19,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 1997 (4 days to check)...\n",
      "  ‚úÖ 1997-07-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1997-07-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1997-09-06: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1997-09-26: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  12%|‚ñà‚ñé        | 4/32 [00:10<01:12,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 1998 (7 days to check)...\n",
      "  ‚úÖ 1998-08-13: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1998-09-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1998-09-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1998-09-11: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1998-09-12: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1998-10-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1998-11-22: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  16%|‚ñà‚ñå        | 5/32 [00:13<01:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 1999 (2 days to check)...\n",
      "  ‚úÖ 1999-08-15: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 1999-10-17: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  19%|‚ñà‚ñâ        | 6/32 [00:16<01:13,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2000 (2 days to check)...\n",
      "  ‚úÖ 2000-08-31: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2000-09-18: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  22%|‚ñà‚ñà‚ñè       | 7/32 [00:19<01:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2001 (3 days to check)...\n",
      "  ‚úÖ 2001-06-02: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2001-07-02: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2001-11-11: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  25%|‚ñà‚ñà‚ñå       | 8/32 [00:21<01:02,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2002 (5 days to check)...\n",
      "  ‚úÖ 2002-06-09: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2002-06-24: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2002-09-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2002-11-11: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2002-11-12: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  28%|‚ñà‚ñà‚ñä       | 9/32 [00:23<00:58,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2003 (3 days to check)...\n",
      "  ‚úÖ 2003-06-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2003-10-07: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2003-10-08: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  31%|‚ñà‚ñà‚ñà‚ñè      | 10/32 [00:26<00:53,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2004 (5 days to check)...\n",
      "  ‚úÖ 2004-06-15: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2004-09-12: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2004-09-13: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2004-09-14: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2004-09-16: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  34%|‚ñà‚ñà‚ñà‚ñç      | 11/32 [00:28<00:48,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2005 (9 days to check)...\n",
      "  ‚úÖ 2005-06-28: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-07-04: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-07-13: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-07-14: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-10-02: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-10-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-10-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-10-21: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2005-12-22: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  38%|‚ñà‚ñà‚ñà‚ñä      | 12/32 [00:30<00:47,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2006 (4 days to check)...\n",
      "  ‚úÖ 2006-06-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2006-07-09: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2006-09-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2006-11-10: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  41%|‚ñà‚ñà‚ñà‚ñà      | 13/32 [00:33<00:48,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2007 (6 days to check)...\n",
      "  ‚úÖ 2007-06-13: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2007-07-04: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2007-08-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2007-09-22: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2007-09-23: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2007-09-24: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 14/32 [00:36<00:49,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2008 (5 days to check)...\n",
      "  ‚úÖ 2008-06-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2008-06-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2008-09-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2008-10-24: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2008-10-26: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 15/32 [00:39<00:45,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2009 (5 days to check)...\n",
      "  ‚úÖ 2009-05-25: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2009-09-05: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2009-09-06: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2009-09-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2009-09-09: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 16/32 [00:41<00:40,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2010 (4 days to check)...\n",
      "  ‚úÖ 2010-10-06: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2010-10-07: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2010-10-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2010-12-06: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 17/32 [00:43<00:37,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2011 (11 days to check)...\n",
      "  ‚úÖ 2011-06-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-06-18: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-06-26: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-07-03: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-07-21: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-08-07: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-08-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-08-09: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-08-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-08-18: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2011-09-01: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 18/32 [00:46<00:36,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2012 (4 days to check)...\n",
      "  ‚úÖ 2012-06-23: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2012-06-24: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2012-09-14: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2012-11-03: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 19/32 [00:49<00:33,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2013 (6 days to check)...\n",
      "  ‚úÖ 2013-06-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2013-06-30: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2013-07-28: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2013-08-27: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2013-10-12: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2013-10-25: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 20/32 [00:51<00:29,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2014 (6 days to check)...\n",
      "  ‚úÖ 2014-06-21: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2014-07-01: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2014-07-03: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2014-08-15: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2014-09-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2014-10-27: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 21/32 [00:53<00:26,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2015 (11 days to check)...\n",
      "  ‚úÖ 2015-01-01: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-06-25: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-06-26: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-06-27: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-07-10: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-07-25: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-07-27: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-07-29: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-08-02: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-09-23: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2015-12-18: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 22/32 [00:56<00:24,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2016 (7 days to check)...\n",
      "  ‚úÖ 2016-05-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2016-07-16: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2016-07-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2016-08-06: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2016-08-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2016-08-21: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2016-09-06: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 23/32 [00:58<00:22,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2017 (13 days to check)...\n",
      "  ‚úÖ 2017-06-12: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-06-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-07-22: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-07-23: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-07-24: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-07-25: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-10-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-10-09: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-10-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-11-15: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-12-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-12-09: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2017-12-10: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 24/32 [01:01<00:20,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2018 (2 days to check)...\n",
      "  ‚úÖ 2018-07-03: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2018-12-16: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 25/32 [01:04<00:19,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2019 (5 days to check)...\n",
      "  ‚úÖ 2019-09-25: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2019-10-24: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2019-10-25: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2019-11-08: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2019-11-09: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 26/32 [01:06<00:15,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2020 (4 days to check)...\n",
      "  ‚úÖ 2020-05-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2020-06-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2020-08-04: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2020-09-01: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 27/32 [01:09<00:13,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2021 (10 days to check)...\n",
      "  ‚úÖ 2021-06-17: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-06-18: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-09-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-09-20: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-09-21: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-10-18: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-10-19: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-12-04: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-12-05: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2021-12-06: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 28/32 [01:12<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2022 (5 days to check)...\n",
      "  ‚úÖ 2022-08-14: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2022-09-11: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2022-09-12: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2022-09-14: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2022-10-24: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 29/32 [01:14<00:07,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2023 (1 days to check)...\n",
      "  ‚úÖ 2023-11-16: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 30/32 [01:16<00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2024 (5 days to check)...\n",
      "  ‚úÖ 2024-05-26: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2024-05-27: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2024-08-01: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2024-09-15: 0.0 ‚Üí 0.0\n",
      "  ‚úÖ 2024-10-25: 0.0 ‚Üí 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 31/32 [01:19<00:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Fetching year 2025 (1 days to check)...\n",
      "  ‚ùå Error: 400 Client Error: Bad Request for url: https://archive-api.open-meteo.com/v1/archive?latitude=22.5626&longitude=88.363&daily=temperature_2m_mean%2Ctemperature_2m_max%2Ctemperature_2m_min%2Csunshine_duration%2Cdaylight_duration%2Cshortwave_radiation_sum&timezone=GMT&start_date=2025-01-01&end_date=2025-12-31\n",
      "  ‚ùå Error: 400 Client Error: Bad Request for url: https://archive-api.open-meteo.com/v1/archive?latitude=22.5626&longitude=88.363&daily=temperature_2m_mean%2Ctemperature_2m_max%2Ctemperature_2m_min%2Csunshine_duration%2Cdaylight_duration%2Cshortwave_radiation_sum&timezone=GMT&start_date=2025-01-01&end_date=2025-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data by year: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [01:27<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error: 400 Client Error: Bad Request for url: https://archive-api.open-meteo.com/v1/archive?latitude=22.5626&longitude=88.363&daily=temperature_2m_mean%2Ctemperature_2m_max%2Ctemperature_2m_min%2Csunshine_duration%2Cdaylight_duration%2Cshortwave_radiation_sum&timezone=GMT&start_date=2025-01-01&end_date=2025-12-31\n",
      "\n",
      "üíæ Saving results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SUCCESS!\n",
      "üìù Updated 171 rows\n",
      "üìÇ Corrected history: data/history_corrected.csv\n",
      "üìã Corrections log: data/corrections_log.csv\n",
      "\n",
      "üìä Statistics:\n",
      "   - Total sunshine added: 0.00 seconds\n",
      "   - Average correction: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Read the zero sunshine days\n",
    "zero_sunshine_df = pd.read_csv('data/zero_sunshine_days.csv')\n",
    "\n",
    "# Read the main history file\n",
    "history_df = pd.read_csv('data/history.csv', comment='#', header=None, skiprows=1)\n",
    "history_df.columns = ['time', 'temperature_2m_mean (¬∞C)', 'temperature_2m_max (¬∞C)', \n",
    "                      'temperature_2m_min (¬∞C)', 'sunshine_duration (s)', \n",
    "                      'daylight_duration (s)', 'shortwave_radiation_sum (MJ/m¬≤)']\n",
    "\n",
    "# Ensure 'time' column is datetime\n",
    "zero_sunshine_df['time'] = pd.to_datetime(zero_sunshine_df['time'])\n",
    "history_df['time'] = pd.to_datetime(history_df['time'])\n",
    "\n",
    "# Base API URL\n",
    "base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Location coordinates\n",
    "params = {\n",
    "    'latitude': 22.5626,\n",
    "    'longitude': 88.363,\n",
    "    'daily': 'temperature_2m_mean,temperature_2m_max,temperature_2m_min,sunshine_duration,daylight_duration,shortwave_radiation_sum',\n",
    "    'timezone': 'GMT'\n",
    "}\n",
    "\n",
    "# Function to fetch data with retry logic and exponential backoff\n",
    "def fetch_api_data(start_date, end_date, max_retries=3):\n",
    "    params_copy = params.copy()\n",
    "    params_copy['start_date'] = start_date\n",
    "    params_copy['end_date'] = end_date\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params_copy, timeout=30)\n",
    "            \n",
    "            # Handle rate limiting\n",
    "            if response.status_code == 429:\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"  ‚ö†Ô∏è  Rate limited. Waiting {wait_time}s before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'time': pd.to_datetime(data['daily']['time']),\n",
    "                'temperature_2m_mean (¬∞C)': data['daily']['temperature_2m_mean'],\n",
    "                'temperature_2m_max (¬∞C)': data['daily']['temperature_2m_max'],\n",
    "                'temperature_2m_min (¬∞C)': data['daily']['temperature_2m_min'],\n",
    "                'sunshine_duration (s)': data['daily']['sunshine_duration'],\n",
    "                'daylight_duration (s)': data['daily']['daylight_duration'],\n",
    "                'shortwave_radiation_sum (MJ/m¬≤)': data['daily']['shortwave_radiation_sum']\n",
    "            })\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"  ‚ö†Ô∏è  Timeout on attempt {attempt + 1}/{max_retries}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Optimize: Group by YEAR instead of month (fewer API calls)\n",
    "# Open-Meteo allows up to 1 year of data per request\n",
    "zero_sunshine_df['year'] = zero_sunshine_df['time'].dt.year\n",
    "years = sorted(zero_sunshine_df['year'].unique())\n",
    "\n",
    "updated_count = 0\n",
    "corrections = []\n",
    "\n",
    "print(f\"üìä Processing {len(zero_sunshine_df)} rows across {len(years)} years\")\n",
    "print(f\"üåê Making approximately {len(years)} API calls...\\n\")\n",
    "\n",
    "for year in tqdm(years, desc=\"Fetching data by year\"):\n",
    "    # Get all dates for this year\n",
    "    year_data = zero_sunshine_df[zero_sunshine_df['year'] == year]\n",
    "    start_date = f\"{year}-01-01\"\n",
    "    end_date = f\"{year}-12-31\"\n",
    "    \n",
    "    print(f\"\\nüìÖ Fetching year {year} ({len(year_data)} days to check)...\")\n",
    "    \n",
    "    api_data = fetch_api_data(start_date, end_date)\n",
    "    \n",
    "    if api_data is not None:\n",
    "        # Update history_df with API data for matching dates\n",
    "        for date in year_data['time']:\n",
    "            api_row = api_data[api_data['time'] == date]\n",
    "            \n",
    "            if not api_row.empty:\n",
    "                api_row = api_row.iloc[0]\n",
    "                hist_mask = history_df['time'] == date\n",
    "                \n",
    "                if hist_mask.any():\n",
    "                    old_sunshine = history_df.loc[hist_mask, 'sunshine_duration (s)'].values[0]\n",
    "                    new_sunshine = api_row['sunshine_duration (s)']\n",
    "                    \n",
    "                    # Only update if old value was 0 and new value is different\n",
    "                    if old_sunshine == 0.0 and new_sunshine is not None:\n",
    "                        # Update all columns\n",
    "                        history_df.loc[hist_mask, 'sunshine_duration (s)'] = new_sunshine\n",
    "                        history_df.loc[hist_mask, 'temperature_2m_mean (¬∞C)'] = api_row['temperature_2m_mean (¬∞C)']\n",
    "                        history_df.loc[hist_mask, 'temperature_2m_max (¬∞C)'] = api_row['temperature_2m_max (¬∞C)']\n",
    "                        history_df.loc[hist_mask, 'temperature_2m_min (¬∞C)'] = api_row['temperature_2m_min (¬∞C)']\n",
    "                        history_df.loc[hist_mask, 'daylight_duration (s)'] = api_row['daylight_duration (s)']\n",
    "                        history_df.loc[hist_mask, 'shortwave_radiation_sum (MJ/m¬≤)'] = api_row['shortwave_radiation_sum (MJ/m¬≤)']\n",
    "                        \n",
    "                        corrections.append({\n",
    "                            'date': date.strftime('%Y-%m-%d'),\n",
    "                            'old_sunshine': old_sunshine,\n",
    "                            'new_sunshine': new_sunshine,\n",
    "                            'difference': new_sunshine - old_sunshine\n",
    "                        })\n",
    "                        updated_count += 1\n",
    "                        print(f\"  ‚úÖ {date.strftime('%Y-%m-%d')}: {old_sunshine} ‚Üí {new_sunshine}\")\n",
    "    \n",
    "    # Rate limit: Wait 1 second between requests (Open-Meteo free tier allows ~10,000 calls/day)\n",
    "    if year != years[-1]:  # Don't wait after the last request\n",
    "        time.sleep(1)\n",
    "\n",
    "# Save results\n",
    "print(f\"\\nüíæ Saving results...\")\n",
    "history_df.to_csv('data/history_corrected.csv', index=False)\n",
    "\n",
    "if corrections:\n",
    "    corrections_df = pd.DataFrame(corrections)\n",
    "    corrections_df.to_csv('data/corrections_log.csv', index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS!\")\n",
    "    print(f\"üìù Updated {updated_count} rows\")\n",
    "    print(f\"üìÇ Corrected history: data/history_corrected.csv\")\n",
    "    print(f\"üìã Corrections log: data/corrections_log.csv\")\n",
    "    print(f\"\\nüìä Statistics:\")\n",
    "    print(f\"   - Total sunshine added: {corrections_df['difference'].sum():.2f} seconds\")\n",
    "    print(f\"   - Average correction: {corrections_df['difference'].mean():.2f} seconds\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No corrections needed - all zero values confirmed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d9b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 1994-05-24 to 1994-05-24...\n",
      "Fetching data for 1994-06-28 to 1994-06-28...\n",
      "Fetching data for 1995-05-10 to 1995-05-16...\n",
      "Fetching data for 1995-07-19 to 1995-07-19...\n",
      "Fetching data for 1995-10-30 to 1995-10-30...\n",
      "Fetching data for 1995-11-01 to 1995-11-09...\n",
      "Fetching data for 1996-06-19 to 1996-06-30...\n",
      "Fetching data for 1996-08-07 to 1996-08-21...\n",
      "Fetching data for 1996-10-27 to 1996-10-28...\n",
      "Fetching data for 1997-07-19 to 1997-07-20...\n",
      "Fetching data for 1997-09-06 to 1997-09-26...\n",
      "Fetching data for 1998-08-13 to 1998-08-13...\n",
      "Fetching data for 1998-09-08 to 1998-09-12...\n",
      "Fetching data for 1998-10-20 to 1998-10-20...\n",
      "Fetching data for 1998-11-22 to 1998-11-22...\n",
      "Fetching data for 1999-08-15 to 1999-08-15...\n",
      "Fetching data for 1999-10-17 to 1999-10-17...\n",
      "Fetching data for 2000-08-31 to 2000-08-31...\n",
      "Fetching data for 2000-09-18 to 2000-09-18...\n",
      "Fetching data for 2001-06-02 to 2001-06-02...\n",
      "Fetching data for 2001-07-02 to 2001-07-02...\n",
      "Fetching data for 2001-11-11 to 2001-11-11...\n",
      "Fetching data for 2002-06-09 to 2002-06-24...\n",
      "Fetching data for 2002-09-10 to 2002-09-10...\n",
      "Fetching data for 2002-11-11 to 2002-11-12...\n",
      "Fetching data for 2003-06-19 to 2003-06-19...\n",
      "Fetching data for 2003-10-07 to 2003-10-08...\n",
      "Fetching data for 2004-06-15 to 2004-06-15...\n",
      "Fetching data for 2004-09-12 to 2004-09-16...\n",
      "Fetching data for 2005-06-28 to 2005-06-28...\n",
      "Fetching data for 2005-07-04 to 2005-07-14...\n",
      "Fetching data for 2005-10-02 to 2005-10-21...\n",
      "Fetching data for 2005-12-22 to 2005-12-22...\n",
      "Fetching data for 2006-06-10 to 2006-06-10...\n",
      "Fetching data for 2006-07-09 to 2006-07-09...\n",
      "Fetching data for 2006-09-20 to 2006-09-20...\n",
      "Fetching data for 2006-11-10 to 2006-11-10...\n",
      "Fetching data for 2007-06-13 to 2007-06-13...\n",
      "Fetching data for 2007-07-04 to 2007-07-04...\n",
      "Fetching data for 2007-08-17 to 2007-08-17...\n",
      "Fetching data for 2007-09-22 to 2007-09-24...\n",
      "Fetching data for 2008-06-17 to 2008-06-19...\n",
      "Fetching data for 2008-09-17 to 2008-09-17...\n",
      "Fetching data for 2008-10-24 to 2008-10-26...\n",
      "Fetching data for 2009-05-25 to 2009-05-25...\n",
      "Fetching data for 2009-09-05 to 2009-09-09...\n",
      "Fetching data for 2010-10-06 to 2010-10-08...\n",
      "Fetching data for 2010-12-06 to 2010-12-06...\n",
      "Fetching data for 2011-06-17 to 2011-06-26...\n",
      "Fetching data for 2011-07-03 to 2011-07-21...\n",
      "Fetching data for 2011-08-07 to 2011-08-18...\n",
      "Fetching data for 2011-09-01 to 2011-09-01...\n",
      "Fetching data for 2012-06-23 to 2012-06-24...\n",
      "Fetching data for 2012-09-14 to 2012-09-14...\n",
      "Fetching data for 2012-11-03 to 2012-11-03...\n",
      "Fetching data for 2013-06-10 to 2013-06-30...\n",
      "Fetching data for 2013-07-28 to 2013-07-28...\n",
      "Fetching data for 2013-08-27 to 2013-08-27...\n",
      "Fetching data for 2013-10-12 to 2013-10-25...\n",
      "Fetching data for 2014-06-21 to 2014-06-21...\n",
      "Fetching data for 2014-07-01 to 2014-07-03...\n",
      "Fetching data for 2014-08-15 to 2014-08-15...\n",
      "Fetching data for 2014-09-20 to 2014-09-20...\n",
      "Fetching data for 2014-10-27 to 2014-10-27...\n",
      "Fetching data for 2015-01-01 to 2015-01-01...\n",
      "Fetching data for 2015-06-25 to 2015-06-27...\n",
      "Fetching data for 2015-07-10 to 2015-07-29...\n",
      "Fetching data for 2015-08-02 to 2015-08-02...\n",
      "Fetching data for 2015-09-23 to 2015-09-23...\n",
      "Fetching data for 2015-12-18 to 2015-12-18...\n",
      "Fetching data for 2016-05-20 to 2016-05-20...\n",
      "Fetching data for 2016-07-16 to 2016-07-17...\n",
      "Fetching data for 2016-08-06 to 2016-08-21...\n",
      "Fetching data for 2016-09-06 to 2016-09-06...\n",
      "Fetching data for 2017-06-12 to 2017-06-20...\n",
      "Fetching data for 2017-07-22 to 2017-07-25...\n",
      "Fetching data for 2017-10-08 to 2017-10-20...\n",
      "Fetching data for 2017-11-15 to 2017-11-15...\n",
      "Fetching data for 2017-12-08 to 2017-12-10...\n",
      "Fetching data for 2018-07-03 to 2018-07-03...\n",
      "Fetching data for 2018-12-16 to 2018-12-16...\n",
      "Fetching data for 2019-09-25 to 2019-09-25...\n",
      "Fetching data for 2019-10-24 to 2019-10-25...\n",
      "Fetching data for 2019-11-08 to 2019-11-09...\n",
      "Fetching data for 2020-05-20 to 2020-05-20...\n",
      "Fetching data for 2020-06-17 to 2020-06-17...\n",
      "Fetching data for 2020-08-04 to 2020-08-04...\n",
      "Fetching data for 2020-09-01 to 2020-09-01...\n",
      "Fetching data for 2021-06-17 to 2021-06-18...\n",
      "Fetching data for 2021-09-19 to 2021-09-21...\n",
      "Fetching data for 2021-10-18 to 2021-10-19...\n",
      "Fetching data for 2021-12-04 to 2021-12-06...\n",
      "Fetching data for 2022-08-14 to 2022-08-14...\n",
      "Fetching data for 2022-09-11 to 2022-09-14...\n",
      "Fetching data for 2022-10-24 to 2022-10-24...\n",
      "Fetching data for 2023-11-16 to 2023-11-16...\n",
      "Fetching data for 2024-05-26 to 2024-05-27...\n",
      "Fetching data for 2024-08-01 to 2024-08-01...\n",
      "Fetching data for 2024-09-15 to 2024-09-15...\n",
      "Fetching data for 2024-10-25 to 2024-10-25...\n",
      "Fetching data for 2025-07-14 to 2025-07-14...\n",
      "\n",
      "‚úÖ Correction complete!\n",
      "Updated 0 rows\n",
      "Corrected history saved to: data/history_corrected.csv\n",
      "Corrections log saved to: data/corrections_log.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Read the zero sunshine days\n",
    "zero_sunshine_df = pd.read_csv('data/zero_sunshine_days.csv')\n",
    "\n",
    "# Read the main history file\n",
    "history_df = pd.read_csv('data/history.csv', comment='#', header=None, skiprows=1)\n",
    "history_df.columns = ['time', 'temperature_2m_mean (¬∞C)', 'temperature_2m_max (¬∞C)', \n",
    "                      'temperature_2m_min (¬∞C)', 'sunshine_duration (s)', \n",
    "                      'daylight_duration (s)', 'shortwave_radiation_sum (MJ/m¬≤)']\n",
    "\n",
    "# Ensure 'time' column is datetime\n",
    "zero_sunshine_df['time'] = pd.to_datetime(zero_sunshine_df['time'])\n",
    "\n",
    "# Group dates into ranges for API efficiency (API allows date ranges)\n",
    "dates_to_check = zero_sunshine_df['time'].dt.date.tolist()\n",
    "\n",
    "# Base API URL\n",
    "base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Location coordinates\n",
    "params = {\n",
    "    'latitude': 22.5626,\n",
    "    'longitude': 88.363,\n",
    "    'daily': 'temperature_2m_mean,temperature_2m_max,temperature_2m_min,sunshine_duration,daylight_duration,shortwave_radiation_sum',\n",
    "    'timezone': 'GMT'\n",
    "}\n",
    "\n",
    "# Function to fetch data for a date range\n",
    "def fetch_api_data(start_date, end_date):\n",
    "    params['start_date'] = start_date\n",
    "    params['end_date'] = end_date\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'time': data['daily']['time'],\n",
    "            'temperature_2m_mean (¬∞C)': data['daily']['temperature_2m_mean'],\n",
    "            'temperature_2m_max (¬∞C)': data['daily']['temperature_2m_max'],\n",
    "            'temperature_2m_min (¬∞C)': data['daily']['temperature_2m_min'],\n",
    "            'sunshine_duration (s)': data['daily']['sunshine_duration'],\n",
    "            'daylight_duration (s)': data['daily']['daylight_duration'],\n",
    "            'shortwave_radiation_sum (MJ/m¬≤)': data['daily']['shortwave_radiation_sum']\n",
    "        })\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {start_date} to {end_date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process dates in monthly chunks to minimize API calls\n",
    "updated_count = 0\n",
    "corrections = []\n",
    "\n",
    "# Group by year-month\n",
    "zero_sunshine_df['year_month'] = zero_sunshine_df['time'].dt.to_period('M')\n",
    "grouped = zero_sunshine_df.groupby('year_month')\n",
    "\n",
    "for period, group in grouped:\n",
    "    start_date = group['time'].min().strftime('%Y-%m-%d')\n",
    "    end_date = group['time'].max().strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Fetching data for {start_date} to {end_date}...\")\n",
    "    \n",
    "    api_data = fetch_api_data(start_date, end_date)\n",
    "    \n",
    "    if api_data is not None:\n",
    "        api_data['time'] = pd.to_datetime(api_data['time'])\n",
    "        \n",
    "        # Update history_df with API data for these dates\n",
    "        for idx, row in api_data.iterrows():\n",
    "            date = row['time']\n",
    "            \n",
    "            # Find matching row in history_df\n",
    "            mask = pd.to_datetime(history_df['time']) == date\n",
    "            \n",
    "            if mask.any():\n",
    "                old_sunshine = history_df.loc[mask, 'sunshine_duration (s)'].values[0]\n",
    "                new_sunshine = row['sunshine_duration (s)']\n",
    "                \n",
    "                if old_sunshine == 0.0 and new_sunshine != 0.0:\n",
    "                    # Update the values\n",
    "                    history_df.loc[mask, 'sunshine_duration (s)'] = new_sunshine\n",
    "                    history_df.loc[mask, 'temperature_2m_mean (¬∞C)'] = row['temperature_2m_mean (¬∞C)']\n",
    "                    history_df.loc[mask, 'temperature_2m_max (¬∞C)'] = row['temperature_2m_max (¬∞C)']\n",
    "                    history_df.loc[mask, 'temperature_2m_min (¬∞C)'] = row['temperature_2m_min (¬∞C)']\n",
    "                    history_df.loc[mask, 'daylight_duration (s)'] = row['daylight_duration (s)']\n",
    "                    history_df.loc[mask, 'shortwave_radiation_sum (MJ/m¬≤)'] = row['shortwave_radiation_sum (MJ/m¬≤)']\n",
    "                    \n",
    "                    corrections.append({\n",
    "                        'date': date.strftime('%Y-%m-%d'),\n",
    "                        'old_sunshine': old_sunshine,\n",
    "                        'new_sunshine': new_sunshine\n",
    "                    })\n",
    "                    updated_count += 1\n",
    "                    print(f\"  Updated {date.strftime('%Y-%m-%d')}: {old_sunshine} ‚Üí {new_sunshine}\")\n",
    "    \n",
    "    # Be respectful to the API - add a small delay\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Save corrected history\n",
    "history_df.to_csv('data/history_corrected.csv', index=False)\n",
    "\n",
    "# Save correction log\n",
    "if corrections:\n",
    "    corrections_df = pd.DataFrame(corrections)\n",
    "    corrections_df.to_csv('data/corrections_log.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Correction complete!\")\n",
    "print(f\"Updated {updated_count} rows\")\n",
    "print(f\"Corrected history saved to: data/history_corrected.csv\")\n",
    "print(f\"Corrections log saved to: data/corrections_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d37407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing with date: 1994-05-24\n",
      "\n",
      "üìä YOUR CURRENT DATA:\n",
      "      time  temperature_2m_mean (¬∞C)  temperature_2m_max (¬∞C)  temperature_2m_min (¬∞C)  sunshine_duration (s)  daylight_duration (s)  shortwave_radiation_sum (MJ/m¬≤)\n",
      "1994-05-24                      26.0                     28.9                     24.4                    0.0               48016.72                             5.98\n",
      "\n",
      "üåê API DATA:\n",
      "Date: 1994-05-24\n",
      "Temperature Mean: 26.0 ¬∞C\n",
      "Temperature Max: 28.9 ¬∞C\n",
      "Temperature Min: 24.4 ¬∞C\n",
      "Sunshine Duration: 0.0 s\n",
      "Daylight Duration: 48016.72 s\n",
      "Shortwave Radiation: 5.98 MJ/m¬≤\n",
      "\n",
      "üîÑ COMPARISON:\n",
      "Your sunshine_duration: 0.0 s\n",
      "API sunshine_duration: 0.0 s\n",
      "‚ö†Ô∏è  NO CHANGE - Both have same value: 0.0 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Read the zero sunshine days\n",
    "zero_sunshine_df = pd.read_csv('data/zero_sunshine_days.csv')\n",
    "\n",
    "# Get the first date with zero sunshine\n",
    "test_date = zero_sunshine_df['time'].iloc[0]\n",
    "print(f\"üîç Testing with date: {test_date}\")\n",
    "\n",
    "# Read your current history data for comparison\n",
    "history_df = pd.read_csv('data/history.csv', comment='#', header=None, skiprows=1)\n",
    "history_df.columns = ['time', 'temperature_2m_mean (¬∞C)', 'temperature_2m_max (¬∞C)', \n",
    "                      'temperature_2m_min (¬∞C)', 'sunshine_duration (s)', \n",
    "                      'daylight_duration (s)', 'shortwave_radiation_sum (MJ/m¬≤)']\n",
    "\n",
    "# Get the existing values for this date\n",
    "existing_row = history_df[history_df['time'] == test_date]\n",
    "\n",
    "print(\"\\nüìä YOUR CURRENT DATA:\")\n",
    "print(existing_row.to_string(index=False))\n",
    "\n",
    "# Fetch from API\n",
    "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "    'latitude': 22.5626,\n",
    "    'longitude': 88.363,\n",
    "    'start_date': test_date,\n",
    "    'end_date': test_date,\n",
    "    'daily': 'temperature_2m_mean,temperature_2m_max,temperature_2m_min,sunshine_duration,daylight_duration,shortwave_radiation_sum',\n",
    "    'timezone': 'GMT'\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"\\nüåê API DATA:\")\n",
    "    print(f\"Date: {data['daily']['time'][0]}\")\n",
    "    print(f\"Temperature Mean: {data['daily']['temperature_2m_mean'][0]} ¬∞C\")\n",
    "    print(f\"Temperature Max: {data['daily']['temperature_2m_max'][0]} ¬∞C\")\n",
    "    print(f\"Temperature Min: {data['daily']['temperature_2m_min'][0]} ¬∞C\")\n",
    "    print(f\"Sunshine Duration: {data['daily']['sunshine_duration'][0]} s\")\n",
    "    print(f\"Daylight Duration: {data['daily']['daylight_duration'][0]} s\")\n",
    "    print(f\"Shortwave Radiation: {data['daily']['shortwave_radiation_sum'][0]} MJ/m¬≤\")\n",
    "    \n",
    "    # Compare\n",
    "    print(\"\\nüîÑ COMPARISON:\")\n",
    "    your_sunshine = existing_row['sunshine_duration (s)'].values[0] if not existing_row.empty else None\n",
    "    api_sunshine = data['daily']['sunshine_duration'][0]\n",
    "    \n",
    "    print(f\"Your sunshine_duration: {your_sunshine} s\")\n",
    "    print(f\"API sunshine_duration: {api_sunshine} s\")\n",
    "    \n",
    "    if your_sunshine == 0.0 and api_sunshine != 0.0:\n",
    "        print(f\"‚úÖ CHANGE DETECTED! API has non-zero value: {api_sunshine} s\")\n",
    "    elif your_sunshine == api_sunshine:\n",
    "        print(f\"‚ö†Ô∏è  NO CHANGE - Both have same value: {your_sunshine} s\")\n",
    "    else:\n",
    "        print(f\"üìù Different values found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error fetching API data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628453a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  temperature_2m_mean (¬∞C)  temperature_2m_max (¬∞C)  \\\n",
      "0  1994-01-01                      20.0                     27.2   \n",
      "1  1994-01-02                      20.0                     27.1   \n",
      "2  1994-01-03                      20.7                     28.2   \n",
      "3  1994-01-04                      21.0                     27.7   \n",
      "4  1994-01-05                      21.6                     28.0   \n",
      "\n",
      "   temperature_2m_min (¬∞C)  sunshine_duration (s)  daylight_duration (s)  \\\n",
      "0                     13.9               35388.50               38813.64   \n",
      "1                     13.4               35337.72               38834.01   \n",
      "2                     14.2               35348.36               38856.03   \n",
      "3                     14.4               35392.11               38879.66   \n",
      "4                     14.7               35311.84               38904.88   \n",
      "\n",
      "   shortwave_radiation_sum (MJ/m¬≤)  \n",
      "0                            16.70  \n",
      "1                            16.64  \n",
      "2                            16.40  \n",
      "3                            16.58  \n",
      "4                            16.39  \n"
     ]
    }
   ],
   "source": [
    "# Rename columns (modify keys if needed)\n",
    "df = df.rename(columns={\n",
    "    \"time\": \"date\",\n",
    "    \"temperature_2m_mean\": \"temp_mean\",\n",
    "    \"temperature_2m_max\": \"temp_max\",\n",
    "    \"temperature_2m_min\": \"temp_min\"\n",
    "})\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f39a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
